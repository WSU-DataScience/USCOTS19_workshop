{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study - The Current\n",
    "\n",
    "* The Current is an alternative radio station\n",
    "* We will pull information about the play list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exercise - Go the the following page and inspect the following </font>\n",
    "\n",
    "* Song title\n",
    "* Artist\n",
    "* Play time\n",
    "* Day, date, period (am/pm)\n",
    "\n",
    "http://www.thecurrent.org/playlist/2014-01-01/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "example_url = 'http://www.thecurrent.org/playlist/2014-01-01/01'\n",
    "s = requests.Session()\n",
    "r = s.get(example_url)\n",
    "\n",
    "soup = bs4.BeautifulSoup(r.content, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull off the period of the day (am/pm)\n",
    "\n",
    "Pull out the \"am\"/\"pm\"\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Search the soup\n",
    "    1. There should be one item returned\n",
    "4. Use soup\\string methods to pull out the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"hour-header open\">\n",
       "      1:00 am to  2:00 am\n",
       "   </span>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I should have used find here...Why?\n",
    "soup('span', class_=\"hour-header open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup('span', class_=\"hour-header open\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"hour-header open\">\n",
       "     1:00 am to  2:00 am\n",
       "  </span>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup('span', class_=\"hour-header open\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n     1:00 am to  2:00 am\\n  '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup('span', class_=\"hour-header open\")[0].next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n     1:00 am ', '  2:00 am\\n  ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup('span', class_=\"hour-header open\")[0].next.split('to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n     1:00 am '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "soup('span', class_=\"hour-header open\")[0].next.split('to')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n     1:00 am'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup('span', class_=\"hour-header open\")[0].next.split('to')[0].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period = soup('span', class_=\"hour-header open\")[0].next.split('to')[0].rstrip()[-2:]\n",
    "period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Breakout activity </font>\n",
    "\n",
    "* Pull out the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title of each song\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Use `soup.findAll` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Use soup/string methods to pull out the title\n",
    "6. Use a list comprehension to process all tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h5 class=\"title\">Holy Roller</h5>,\n",
       " <h5 class=\"title\">Kingdom of Rust</h5>,\n",
       " <h5 class=\"title\">Black Dog</h5>,\n",
       " <h5 class=\"title\">Turn It Around</h5>,\n",
       " <h5 class=\"title\">Flavor of the Month</h5>,\n",
       " <h5 class=\"title\">Potential Wife</h5>,\n",
       " <h5 class=\"title\">24 Hours</h5>,\n",
       " <h5 class=\"title\">Who's Gonna Shoe Your Pretty Little Feet?</h5>,\n",
       " <h5 class=\"title\">Marigold</h5>,\n",
       " <h5 class=\"title\">High Road</h5>,\n",
       " <h5 class=\"title\">The Vampyre Of Time and Memory</h5>,\n",
       " <h5 class=\"title\">Valerie Plame</h5>,\n",
       " <h5 class=\"title\">Morning Song</h5>,\n",
       " <h5 class=\"title\">(You Will) Set The World On Fire</h5>,\n",
       " <h5 class=\"title\">Sixteen Saltines</h5>,\n",
       " <h5 class=\"title\">Wave of Mutilation</h5>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.findAll('h5', class_ = \"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h5 class=\"title\">Holy Roller</h5>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tag =  soup.findAll('h5', class_ = \"title\")[0]\n",
    "example_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Holy Roller'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tag.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Holy Roller'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tag.next.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Holy Roller',\n",
       " 'Kingdom of Rust',\n",
       " 'Black Dog',\n",
       " 'Turn It Around',\n",
       " 'Flavor of the Month',\n",
       " 'Potential Wife',\n",
       " '24 Hours',\n",
       " \"Who's Gonna Shoe Your Pretty Little Feet?\",\n",
       " 'Marigold',\n",
       " 'High Road',\n",
       " 'The Vampyre Of Time and Memory',\n",
       " 'Valerie Plame',\n",
       " 'Morning Song',\n",
       " '(You Will) Set The World On Fire',\n",
       " 'Sixteen Saltines',\n",
       " 'Wave of Mutilation']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = [tag.next.strip() for tag in soup.findAll('h5', class_ = \"title\")]\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Break out session - Name of the Artist </font>\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Use `soup.findAll` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Use soup/string methods to pull out the title\n",
    "6. Use a list comprehension to process all tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Break out session - song start time </font>\n",
    "\n",
    "1. Inspect the element\n",
    "    1. This one is tricky\n",
    "    2. Time tag does not have a tag, but\n",
    "    3. The surrounding div does have a class\n",
    "2. Identify the html tag and class\n",
    "3. Use `soup.findAll` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Use soup/string methods to pull out the title\n",
    "6. Use a list comprehension to process all tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_period(soup):\n",
    "    search = soup('span', class_=\"hour-header open\")\n",
    "    if len(search) > 0:\n",
    "        return search[0].next.split('to')[0].rstrip()[-2:]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_day(soup):\n",
    "    search = soup('a', class_=\"start-picker\")\n",
    "    if len(search) > 0:\n",
    "        return search[0].next.split(',')[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_song_info(url):\n",
    "    print(\"Starting {0} urls\".format(url))\n",
    "    date = url.split('/')[-2]\n",
    "    s = requests.Session()\n",
    "    r = s.get(url)\n",
    "    soup = bs4.BeautifulSoup(r.content, 'lxml')\n",
    "    period = get_period(soup)\n",
    "    day_of_week = get_day(soup)\n",
    "    soup = bs4.BeautifulSoup(r.content)\n",
    "    titles = [t.next.strip() for t in soup.findAll('h5', class_=\"title\")]\n",
    "    artists = [a.next.strip() for a in soup.findAll('h5',class_='artist')]\n",
    "    times = [d.time.next.strip() for d in soup('div', class_=\"two columns songTime\")]\n",
    "    song_info = [(day_of_week, date, time, period, title, artist) \n",
    "             for time, title, artist in zip(times, titles, artists)]\n",
    "    return song_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting http://www.thecurrent.org/playlist/2014-01-01/01 urls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:59',\n",
       "  'am',\n",
       "  'Holy Roller',\n",
       "  'Thao and The Get Down Stay Down'),\n",
       " ('Wednesday', '2014-01-01', '1:54', 'am', 'Kingdom of Rust', 'Doves'),\n",
       " ('Wednesday', '2014-01-01', '1:51', 'am', 'Black Dog', 'Frankie Lee'),\n",
       " ('Wednesday', '2014-01-01', '1:46', 'am', 'Turn It Around', 'Lucius'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:44',\n",
       "  'am',\n",
       "  'Flavor of the Month',\n",
       "  'The Posies'),\n",
       " ('Wednesday', '2014-01-01', '1:38', 'am', 'Potential Wife', 'Strange Names'),\n",
       " ('Wednesday', '2014-01-01', '1:34', 'am', '24 Hours', 'Sky Ferreira'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:31',\n",
       "  'am',\n",
       "  \"Who's Gonna Shoe Your Pretty Little Feet?\",\n",
       "  'Billie Joe and Norah'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:27',\n",
       "  'am',\n",
       "  'Marigold',\n",
       "  'J. Roddy Walston and The Business'),\n",
       " ('Wednesday', '2014-01-01', '1:23', 'am', 'High Road', 'Cults'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:19',\n",
       "  'am',\n",
       "  'The Vampyre Of Time and Memory',\n",
       "  'Queens of the Stone Age'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:13',\n",
       "  'am',\n",
       "  'Valerie Plame',\n",
       "  'The Decemberists'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:09',\n",
       "  'am',\n",
       "  'Morning Song',\n",
       "  'The Avett Brothers'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:05',\n",
       "  'am',\n",
       "  '(You Will) Set The World On Fire',\n",
       "  'David Bowie'),\n",
       " ('Wednesday', '2014-01-01', '1:03', 'am', 'Sixteen Saltines', 'Jack White'),\n",
       " ('Wednesday', '2014-01-01', '1:01', 'am', 'Wave of Mutilation', 'Pixies')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_song_info(example_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting a years worth of data\n",
    "\n",
    "## Step 1 - Identify the url pattern\n",
    "\n",
    "The Current uses urls of the following pattern\n",
    "\n",
    "    'http://www.thecurrent.org/playlist/2017-05-04/10'\n",
    "\n",
    "or \n",
    "\n",
    "    'http://www.thecurrent.org/playlist/year-month-day/hour'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: How might you generate all combinations for a given year?\n",
    "\n",
    "**Answer:** Python has a tool for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numdays = 365\n",
    "base = datetime.datetime.today()\n",
    "dts = [base - datetime.timedelta(hours = h) for h in range(0, numdays*24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def output_address(dt):\n",
    "    fmt = 'http://www.thecurrent.org/playlist/%Y-%m-%d/%H'\n",
    "    return dt.strftime(fmt)\n",
    "\n",
    "def test_output_address():\n",
    "    date = datetime.datetime(2000,1,1,1)\n",
    "    assert output_address(date) == 'http://www.thecurrent.org/playlist/2000-01-01/01'\n",
    "test_output_address()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.thecurrent.org/playlist/2019-05-13/09',\n",
       " 'http://www.thecurrent.org/playlist/2019-05-13/08',\n",
       " 'http://www.thecurrent.org/playlist/2019-05-13/07',\n",
       " 'http://www.thecurrent.org/playlist/2019-05-13/06',\n",
       " 'http://www.thecurrent.org/playlist/2019-05-13/05',\n",
       " 'http://www.thecurrent.org/playlist/2019-05-13/04',\n",
       " 'http://www.thecurrent.org/playlist/2019-05-13/03',\n",
       " 'http://www.thecurrent.org/playlist/2019-05-13/02',\n",
       " 'http://www.thecurrent.org/playlist/2019-05-13/01',\n",
       " 'http://www.thecurrent.org/playlist/2019-05-13/00']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = [output_address(d) for d in dts]\n",
    "urls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from toolz import pipe\n",
    "from toolz.curried import take\n",
    "from more_itertools import side_effect, consume\n",
    "\n",
    "\n",
    "with open('the_current_last_year_new.csv', 'w') as outfile:\n",
    "    header = \"Weekday,Date,Time,Period,Song_Title,Artist\"\n",
    "    print(header, file=outfile)\n",
    "    count = 0\n",
    "    for url in urls:\n",
    "        for song_info in get_song_info(url):\n",
    "            count += 1\n",
    "            if count % 5 == 0:\n",
    "                print(\"Processed {0} songs\".format(count))\n",
    "            join_info = \",\".join(song_info)\n",
    "            print(join_info, file=outfile)\n",
    "            if count % 1000 == 0:\n",
    "                print(\"Flushing output\")\n",
    "                outfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
